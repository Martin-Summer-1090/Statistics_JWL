# **Introduction**

What is the biggest source of electricity production in Kenya? Answering 
this question needs data listing and recording various forms of 
electricity production in specific countries. An internationally 
acknowledged organisation, which collects and reports these data 
is the International Energy Agency (IEA). 

:::{.callout-tip}
## Accessing IEA data on the internet

If you have access to the internet,
you can look up data and reports by the IEA on it's website
https://www.iea.org/ 
:::



Now let's take a quiz and guess. What do you think is
actually the biggest source of electricity production in Kenya?

1. Coal
2. Renewable energy
3. Natural gas

Consulting the IEA data, you will find that the correct answer 
is *renewable energy*. A very interesting website 
called *gapminder*, which analyzes the answers of
many people to this question, finds that 61 % give a wrong answer to this
question. Maybe they find it hard to imagine that 80 % of energy production in 
Kenya is already fossil free thanks to huge 
sources of geothermal- and hydropower.^[Geothermal electricity generation uses the earth's natural heating energy - geothermal energy. A country needs to be located on a geothermal hot spot to make effective use of this enegry source for electricity generation. At such a hotspot there are high temperatures beneath the earth's surface which naturally produces steam. This steam can be used to spin turbines connected to a generator. This mechanism then produces electricity. Hydropower uses  the water cycle to generate electricity by using dams to alter the flow of a river. The kinetic energy of the water spins tubrines connected to a generator which produces electricity.]  Even if you break the answers down by
country you see that 38 % of people from Kenya get the answer wrong. Among
the people from the UK, who answer this question even 72 % answer wrongly.

If you are not familiar with the details of electricity production using 
geothermal- and hydropower or if you are not completely sure how 
to interpret a number like 38 %, don't worry for now. The point here is 
that you see that one useful consequence of being able to access, read and 
interpret data is that it can help to establish facts about the world. In this
way data canÂ´
help us to perhaps correct misconceptions we might have had about these
facts. 

:::{.callout-tip}
## The gapminder webpage
If you have internet access you can reach the gapminder webpage at https://www.gapminder.org/). I encourage you to visit this page at an occasion 
when you have access to the internet. You will be surprised how often you
might have a wrong guess about basic facts in the world.
:::

In this course you will learn how to work with data and how to learn from these
data in a systematic way. 

Learning from data entails more than just establishing
facts. This might not always be possible, either because you cannot access the
relevant data or you cannot completely access them, since doing so would be
way too expensive. When working with data you also need rigorous definitions
of concepts, so that you can transform your experience about the world into
data

Think for a moment about the following interesting 
example, which I learned from a wonderful book by the British 
statistician David Spiegelhalter [@Spi2019]. The example shows that even
just categorizing and labeling things in the world to measure them and turn
them into data can be challenging. A very basic question raised in 
the introduction of this book is:

::: {.callout-note icon=false}

## Question:

How many trees are there on the planet?

:::

It is clear that answering this question is more challenging than the task 
the IEA had to solve when listing energy sources by country around the world 
in a given time period. 
But before you go about to think how you might count all the trees on
the planet, you have to answer
an even more basic question, namely: What is a tree? Some of you might think
this is a silly and obvious question, which every child can answer. But 
what some might consider a tree others will consider just a shrub. 
Turning experience into data requires rigorous definitions. It turns out 
that such definitions can be given for trees. ^[For example the 
forestry expert Michael Kuhns writes: "...*Though no scientific definition exists to separate trees and shrubs, a useful definition for a tree is a woody plant having one erect perennial stem (trunk) at least three inches in diameter at a point 4-1/2 feet above the ground, a definitely formed crown of foliage, and a mature height of at least 13 feet. This definition works fine, though some trees may have more than one stem and young trees obviously don't meet the size criteria. A shrub can then be defined as a woody plant with several perennial stems that may be erect or may lay close to the ground. It will usually have a height less than 13 feet and stems no more than about three inches in diameter.*" [@Kuh]] 

But even with the definition at
hand you cannot just go around the planet and count every plant that meets the
criteria. So this is what the researchers investigating that question 
did according to [@Spi2019]: 

"...*They first took a series of of areas with a common type of landscape, known as a biome and counted the average number of trees per square kilometer. They then used satellite imaging to estimate the total area of the planet covered by each type of biome, carried out some complex statistical modelling, and eventually came up with an estimate of 3.04 trillion (3,040,000,000,000) trees on the planet. This sounds a lot, except that they reckoned there used to be twice this number*."

Now imagine that if long expert discussions are needed to precisely 
define something
so seemingly obvious as a tree, clearly more complex concepts
such as unemployment or the definition of the total value of goods ans services
produced in a country in a given year, known as Gross Domestic Product 
or GDP, is
even more challenging. 

There is no automatism or mechanical receipt how we can 
turn experience into data
and the statistics that we use and produce are constructed on the basis of
judgement. It is a starting point for a deeper understanding of the world 
around us. This is one of the reasons why in this course statistics is
not only referred to as science, which it arguably is to some degree, but also
as an art.

One of the limitations of data as a source of knowledge about the world is
that anything we choose to measure will differ across places, across persons
or across time. When analyzing and trying to understand data we will always
face the problem how we can extract meaningful insights from this
apparent random variation. One challenge faced by statistics and one
core topic in this course will thus be how we can distinguish in data the
important relationships from the unimportant background variability. 

Exploring and finding such meaningful relationships or patterns 
in data using the
science of statistics and computational tools is one of the skills you will
learn in this course.

An example of a pattern in data is if we can spot a trend, data values 
which are for example increasing or decreasing.

Consider the following data from the world bank, reporting the 
share of people in the world who are living in extreme poverty. 
Extreme poverty is defined by the World Bank, an international 
development finance organisation for low and middle income countries located in the US^[The Worldbank is an international financial institution founded along with the International Monetary Fund in the Bretton Wods conference in 1944. It is located in Washington D.C. and finances projects in low and middle income countries. It also collects and processes data globally to support its activities and conduct development research. The Worldbank makes its data public in print or through its website https://www.worldbank.org/en/home] as the percentage 
of people in the world who
have to live on less that $ 1.90 per day. 

Let us have a look at a table showing the first 10 observations of this
share

```{r}
#| label: tbl-example-poverty
#| tbl-cap: "Share of world polpulation living in extreme poverty, Source: World Bank"


# read poverty data from our project data folder
povdat_by_country <- read.csv("data/extreme_poverty/share-of-population-in-extreme-poverty.csv")
# select the years from 2000
povdat_world <- with(povdat_by_country, povdat_by_country[Entity == "World" & Year >= 2000, ])
# Keep only the year and the share
plot_data <- povdat_world[,c(3,4)]
# Rename variables
names(plot_data) <- c("Year", "Share")

# produce a table
library(knitr)
kable(head(plot_data, n= 10), row.names = F, digits = 1)
```

The table shows that the share of people living in extreme poverty has been decreasing year
after year for the first 10 years since the year 2000. This is a pattern which is called a
*downward trend*. 

Note that we did not show the whole series of numbers. The data points in our data-set actually
range until the year 2017. Printing them all in a table quickly produces very large and unwieldy
number arrays which are awkward to read.

Exploring data and detecting patterns is usually easier when we use the power of the human
visual system. Humans are very good in finding visual patterns. Looking for patterns is almost
viscerall for us. We can't help but looking for patterns. This almost instinctive human urge can
also be misleading and suggesting patterns to us where there are in fact none. In data
exploration we can make use of the power of visualization by plotting data and looking at them
graphically. The modern computer has made this form of displaying data particularly easy and
powerful and visualizing data in data exploration is another core skill you are going to
learn in this course.

So let us visualize the world poverty data. In our plot we draw the year on  the x-axes and
the share of people living in extreme poverty on the y-axes. This will give us a point for each
year. To facilitate the spotting of a trend, we connect the annual observations by a line.

```{r}
#| label: fig-share-of-people-in-extreme-poverty-world
#| fig-cap: Share of world population living in extreme poverty from 2000 - 2017
#| warning: false

library(ggplot2)

p <- ggplot(plot_data, aes(x = Year, y = Share)) + 
     geom_line() +
     geom_point() +
     xlab("")
p
```


Visualizing trends in world extreme poverty as an example of data
exploration. In this case the data pattern reveals a stunning fact. Over almost
two decades we can see a sharp fall in the share of extremely poor people when looked
at from a global perspective. Of course when we drill down to the level of individual
countries this trend will not look the same everywhere and there might be countries where the
share has actually increased. But overall we have seen a breathtaking steady decline. This is
good news.^[When you have access to the internet you can have a closer look at these data
at the very interesting website "our world in data" maintained by a consortium of Oxford University
and University College London. See https://ourworldindata.org/extreme-poverty. The website has
many interesting visualizations and options to select individual countries, country aggregates and
make other selections of the data.]

But does this trend mean that extreme poverty must disappear some years down the road? No, because
nobody can tell whether the trend of the last two decades will go on also in the future.

Statistics can help us to think more systematically about patterns and in 
making systematic guesses how a pattern might continue in the future. 
This is another core skill you will learn in this course: Making predictions, which 
means using available data and information to make informed guesses 
about data and information we do not have.

Let us go back to the share of people in the world living in extreme poverty. As
reported in our data the last actual observation for the global share in extreme
poverty from the world bank is from 2017. There are more recent data for some regions
but the data since then are by now forecasts based on statistical techniques. The
basic ideas of these techniques and how to apply them to data is a core skill you will learn
in this course.

Now what does the World bank predict for the share of extreme poverty in the world? Let
us look at the data again graphically to visualize the prediction.

```{r}
#| label: fig-share-of-people-in-extreme-poverty-world-forecast
#| fig-cap: Share of world population living in extreme poverty from 2000 - 2017 with predictions until 2021
#| warning: false

obsdat <- data.frame(Year = plot_data$Year, Scenario = rep("Observed", 18), Share = plot_data$Share)

pred_dat_precovid <- data.frame(Year = c(2018, 2019, 2020, 2021), Scenario = rep("Pre-Covid-19", 4), Share = c(8.6, 8.4, 7.9, 7.5))

pred_dat_covidbase <- data.frame(Year = c(2018, 2019, 2020, 2021), Scenario = rep("Covid-19-Baseline", 4), Share = c(8.6, 8.4, 9.1, 8.9))

pred_dat_coviddown <- data.frame(Year = c(2018, 2019, 2020, 2021), Scenario = rep("Covid-19-Downside", 4), Share = c(8.6, 8.4, 9.4, 9.4))



p <- ggplot(obsdat, aes(x = Year, y = Share)) + 
  geom_point(aes(color="Observed")) + 
  geom_line(aes(color = "Observed")) +
  geom_point(data = pred_dat_precovid, aes(color = "Pre-Covid-19")) +
  geom_line(data = pred_dat_precovid, aes(color = "Pre-Covid-19")) +
  geom_point(data = pred_dat_covidbase, aes(color = "Covid-19-Baseline")) +
  geom_line(data = pred_dat_covidbase, aes(color = "Covid-19-Baseline")) +
  geom_point(data = pred_dat_coviddown, aes(color = "Covid-19-Downside")) +
  geom_line(data = pred_dat_coviddown, aes(color = "Covid-19-Downside"))
  xlab("")

p
```


Example, take falling trend in poverty, make prediction
on the trend, show that corona for the first time in many years reversed the
trend look for the gapminder example.

this can then lead to the third point, quantifying uncertainty.


Introduce the concept of statistics and give an overview what students will learn during the course. In the introductory unit I would like to include an activity on variation or an interesting visualization where students see the code (which they do not yet understand in detail) but can change certain details and experiment on the computer how the visualization changes. This will also provide a first check of whether the software and hardware work for each student. I would also like to discuss why statistics is important and get students involved by collecting data on them for use later in the course. I would like to have lots of involvement in the first unit to set expectations for plenty of participation.

The overall goals of this course might be described as follows: After successfully completing this course students will have learned new skills in three core pillars of statistics

1.  Data exploration or finding patterns in data and information through visualisation and computation.

2.  Making predictions, which means using available data and information to make informed guesses about data and information we do not have.

3.  To quantify the uncertainty we have to attach to our predictions.

Simultaneously with these three core skills the students will learn to use the computer and modern computing tools to apply this knowledge to real world data. The combination of these skills will empower students to achieve a level of data literacy allowing them to independently work with new data and new situations they encounter in their professional life after completing the course or in their further studies.

As sources for my notes I rely very much on [@FrePisPur2009] on [@Kap2009] and in particular on Spiegelhalter's wonderful exposition [@Spi2019] in terms of concepts and the logic how the concepts are developed. Important sources for examples are \[@BekKes2021\], \[@GelNol2017\] as well as [@PeCa2005] as well as [@AdhDen], who wrote the textbook for Berkeley's introductory data science course Data08.

My vision would be to achieve a suitably adapted combination of Spiegelhalter and Adhikari, DeNero and Wagner. While the former is the didactically best exposition of statistics I have ever encountered, the latter is unmatched in explaining modern computational tools at a basic level. For this course, however both sources need to be substantially reworked. Spiegelhalter is written for a general audience of readers. Here we need to teach the concepts and actively involve students through exercises and projects they do themselves. I will thus follow the conceptual development logic of Spiegelhalter -- and in this lecture note outline I have literally done so -- but I would like to find a different and more interactive exposition with perhaps also different examples, nearer to the live context of students. Adhikari, DeNero and Wagner is for this course a bit too much tilted towards computation and perhaps not enough towards statistics. On the other hand this is a lightening rod for how I would like to see this course roughly turn out in terms of exposition and the use of the computational tools, in particular notebooks and coding style.
